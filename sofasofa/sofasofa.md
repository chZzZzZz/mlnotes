#卷1
1. 已知坐标轴中两点A(2,−2)
，B(−1,2)，求这两点的曼哈顿距离（L1距离）。
解：L1 = |2--1|+|-2-2|=7

2. SVM中的核技巧（Kernal trick）的作用包括以下哪项？
【美国搜索引擎】
	A. 特征升维
	B. 特征降维
	C. 防止过拟合  
解：A  

3. 在数据预处理阶段，我们常常对数值特征进行归一化或标准化(standardization, normalization)处理。这种处理方式理论上不会对下列哪个模型产生很大影响？
【美国社交网站、美国搜索引擎】
	A. k-Means
	B. k-NN
	C. 决策树  
解：C。 k-means与knn都与距离有关。而决策树对于数值特征，只在乎其大小排序，而非绝对大小。不管是标准化或者归一化，都不会影响数值之间的相对大小。关于决策树如何对数值特征进行划分:
    (1)首先对这个连续变量排序。比如说年龄，把所有样本中年龄的数值从小到大排序。
    (2)在数据没有重复的假设下，如果有n个样本，那么排序后的数据之间应该有n-1个间隔。
    (3)决策树会对这n-1个间隔进行逐一尝试（分叉），每个不同的分叉，会带来不同的gini指数，我们最终选gini指数最小的那个分叉作为最优分叉，也就是阈值。
假如训练集上有Age这么个特征，数值分别为
10，11， 16， 18， 20， 35
那么在这个节点上，算法会自动考虑下面几种划分的可能

age<=10 and age>10 

age<=11 and age>11 

age<=16 and age>16

age<=18 and age>18

age<=20 and age>20
六个数值点，所以就有5个对应划分的可能。对这5个可能一一尝试，选出基尼指数最小的那个。   
4. 下面哪个情形不适合作为K-Means迭代终止的条件？
【美国社交网站】
	A. 前后两次迭代中，每个聚类中的成员不变
	B. 前后两次迭代中，每个聚类中样本的个数不变。
	C. 前后两次迭代中，每个聚类的中心点不变  
解：B

5.关于欠拟合（under-fitting），下面哪个说法是正确的？
【国内新闻app】
A. 训练误差较大，测试误差较小
A. 训练误差较小，测试误差较大
C. 训练误差较大，测试误差较大  
解：C

#卷2
1. 下列哪个方式能防止决策树过拟合？
   A. 剪枝
   B. 增加训练集中样本数量
   C. 采用并行计算寻找分叉点  
解：A
    
2. 和单个决策树相比，随机森林做到了
	A. 减小偏差(bias)
  	B. 减小方差(variance)
  	C. 既减小偏差(bias)又减小方差(variance)  
解：B 随机森林主要是bagging的思想，而没有boosting的思想。所以没有减小偏差，只减小了方差。  

3. 下列哪个表达式是Ridge的正则项？

   A. ∥β∥22

   B. ∥β∥2
   C. ∥β∥1  
解：A Ridge的正则项是二范数的平方。  
4. 如果用神经网络进行二元分类，那么最常用的输出层函数是

   A. Linear
   B. Sigmoid
   C. ReLU  
解：B  
5. 下面哪个算法是监督式学习？

   A. PCA
   B. 最小二乘回归
   C. 高斯混合模型（GMM）  
解：A

#卷3
1. 在整个实数集上，下列哪个函数不是凸函数？

   A. x4+x

   B. x4+x2
   C. x4+x3  
解：C  对于光滑函数，如果其二次导数非负，则为凸函数。C选项的二次导数为12x2+6x，并不是恒为非负。  

2. 朴素贝叶斯模型(naive Bayes)是基于下列哪个前提假设？

  	A. 特征近似同分布
   	B. 特征独立
   	C. 误差项服从均值为0的分布  
解：B 朴素贝叶斯中的“朴素”二字突出了这个算法的简易性。朴素贝叶斯的简易性表现该算法基于一个很朴素的假设：所有的变量都是相互独立的。  
3. Bagging方法更适用以下哪种情形？

   A. 原模型预测结果方差（variance）大，偏差（bias）小
   B. 原模型预测结果方差（variance）小，偏差（bias）大
   C. 与偏差、方差无关  
解：A  
4. 对于一个有三个隐层的神经网络，如果激活函数全部采用线性函数，输出层采用sigmoid函数，那么这个神经网络在形式上与下列哪种模型等价？

   A. 单个决策树
   B. 三个决策树的混合模型
   C. 逻辑回归  
答案是C。因为除了输出层，其他层都是线性的，这相当于是线性模型。最后的输出层是sigmoid函数，等价于logistics函数，所以说是等价于逻辑回归。  
5. 对于分类模型，训练不当，会存在过拟合现象。回归模型中也存在过拟合这种现象吗？

   A. 不会
   B. 会  
解：B  

#卷4
1. 已知坐标轴上的两个A(2,1),B(5,5)，那么这两点的欧氏距离是多少？

   A. 5
   B. 9
   C. 25  
解： A。 Lp = (sum(|xi-xj|)^p)^(1/p) p=2,欧式距离；p=1,曼哈顿距离。  
2. 对于k-NN的决策边界，下面说法正确的是？

   A. 当我们增大k，决策边界会变得更光滑
   B. 当我们减小k，决策边界会变得更光滑
   C. 决策边界的光滑程度与k无关  
解答：选A。  
3. 假设我们用GridSearch对随机森林模型进行调参，参数包括树的个数：候选取值为100，150，200,
树的最大深度：4，5，6,那么在整个GridSearch过程中，我们需要多少次模型验证？

   A. 3
   B. 6
   C. 9  
解：A  
4. 对于监督式学习，训练不当，会存在过拟合现象。无监督式学习中也存在过拟合这种现象吗？

   A. 不会
   B. 会  
解：不光是聚类，其他非监督学习的算法也会出现过拟合。
过拟合的本质就是过分地学习了训练样本中的噪音杂质，从而削弱了泛化能力。
比如PCA，如果样本中有一些离谱的噪点，PCA算法的损失函数就会很大程度地被噪点影响。当你把训练出来的PCA作用在新的数据集上的时候，你得到的结果也许就非常离谱，因为你对训练集过拟合了。
同样的问题也会出现在autoencoder上，在某个数据集上训练出一个autoencoder，网络中的权重或者结构可以用来重建原数据。当你的损失函数没有考虑到正则化的时候或者你的网络很复杂的时候，autoencoder很可能出现过拟合，训练好的autoencoder在新的数据集上作用之后，输出的数值就未必能够复原新数据集了。  
5. 下列哪种模型不能用于回归？
   A. k-NN
   B. 逻辑回归
   C. 决策树  
解：B

#卷5
1. 关于矩阵的奇异值(singular values)，下列说法正确的是

   A. 只有方阵才存在奇异值
   B. 奇异值可能是正数也可能是负数
   C. 非零奇异值的个数与矩阵的秩(rank)有关  
解：奇异值非负，正奇异值的个数等于矩阵的秩。  
2. 下列哪种矩阵是稀疏矩阵(sparse matrix)？

   A. 矩阵中大多数元素都是缺失值
   B. 矩阵中大多数元素都是零
   C. 矩阵的特征值(eigenvalues)大多数为零  
解：在矩阵中，若数值为0的元素数目远远多于非0元素的数目，并且非0元素分布没有规律时，则称该矩阵为稀疏矩阵。  

#卷6
1. 关于优化算法，下列说法正确的是

   A. 梯度下降是一阶优化算法，牛顿法是一阶优化算法
   B. 梯度下降是二阶优化算法，牛顿法是一阶优化算法
   C. 梯度下降是一阶优化算法，牛顿法是二阶优化算法  
解：C  

2. 对于一个二元分类任务，已知测试集中三个样本的真实标签为0，1，1，模型的预测概率为0.2, 0.8, 0.8。这个模型在这个测试集上的logloss是多少？已知log(0.2)=−1.609，log(0.8)=−0.223

   A. 0.223
   B. 1.609
   C. 0.685  
解：A  
3. 下列哪个方式不能对随机森林起到剪枝的效果？

   A. 控制树的深度
   B. 控制树的个数
   C. 控制叶结点上样本的个数  
解：B 树的个数与“剪枝”无关。A与C都可以达到剪枝的效果。  
4. 如果我使用数据集的全部特征并且能够达到100%的准确率，但在测试集上仅能达到70%左右，这说明：

   A. 这是个很好的模型
   B. 这个模型过拟合
   C. 这个模型欠拟合  
解： B  

5. 对于多层前馈神经网络，使用下面哪种激活函数可较好防止梯度消失(vanishing gradient)现象？

   A. ReLU
   B. Sigmoid
   C. tanh  
解：A  ReLU函数主要作用是防止梯度弥散，加快计算，具备稀疏激活性。
sigmoid的导数最大为1/4，只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近0，这会造成梯度弥散。relu函数在大于0的部分梯度为常数1，所以不会出现梯度弥散，relu函数在负半区的导数为0，所以一旦神经元激活值进入负半区梯度就会为0，也就说神经元不会经历训练，即稀疏性。relu函数的导数计算更快。

#卷7
1. 关于混淆矩阵(confusion matrix)，下列说法正确的是

   A. 混淆矩阵中所有元素的和是样本的个数
   B. 混淆矩阵中所有元素的和是特征的个数
   C. 混淆矩阵中所有元素的和是被正确分类的样本的个数  
解：A  
2. 下面哪种方法不能帮助k-NN解决维度灾难(curse of dimensionality)的问题？

   A. 对数据进行降维
   B. 对特征进行标准化处理
   C. 进行特征选择  
解：B  
3. 在决策树的一个叶结点中阳性样本、阴性样本正好各半，那么这个叶结点的香农熵(Shannon entropy）是多少？

   A. 0
   B. 0.5
   C. 1  
解：C  当一个叶节点只有一类标签时，熵取最小值为0；当两类标签各一半时，熵取最大值，为1。
香农熵=-sum（Pi*log2Pi）  

4. 线性SVM在下列那种情况下表现糟糕：

   A. 线性可分数据
   B. 含噪声数据与重叠数据点
   C. 标准化过的数据  
解：B  

5. 针对二元分类任务，对于一个只有两个特征(分别为X1,X2)的数据集，下面决策边界（绿色斜线）不可能是以下哪种算法的？

   A. 决策树
   B. kNN
   C. SVM  
解：A  决策树的决策边界必须与座标轴垂直。

#卷8
1. 对于连续随机变量的概率密度函数(Probability Density Function， PDF)，下列说法正确的是

   A. PDF的最大值不能超过1
   B. PDF的最大值可以为1，但不能大于1
   C. PDF的最大值可能大于1  
解：C  
2. 对于连续随机变量的累积分布函数(Cumulative Distribution Function， CDF)，下列说法正确的是

   A. CDF的值必须小于1
   B. CDF的最大值可以为1，但不能大于1
   C. CDF的最大值可能大于1  
解：B  
3. 抛两枚公平的硬币，已知至少一个硬币是正面，两个硬币都是正面的概率是

   A. 1/4
   B. 1/3
   C. 1/2  
解：B  正面记为H，反面记为T。至少有一个正面，一共有三种情况，{HH,HT,TH}。两个都是正面的概率则为1/3。  

4. 本周有七场车祸，这七场车祸正好发生在同一天的概率是多大？

   A. 7/2^7
   B. 1/7^6
   C. 1/7^7
解：B  C（7，1）1/7^7  
5. 今天下雨的概率是0.5，明天下雨的概率是0.6，今天或者明天下雨的概率是0.7，今天和明天都下雨的概率是多少？

   A. 0.4
   B. 0.3
   C. 0.2  
解：A  画维氏图解：0.5+0.6-0.7=0.4

#卷9
1. 下面哪个统计量可能大于1？

   A. logloss
   B. ROC AUC
   C. 皮尔逊相关系数  
解：A  logloss的取值范围是0到正无穷。
2. 混淆矩阵可以不能用来评估下面哪类模型的表现？

   A. 二元分类器
   B. 多元分类器
   C. 聚类算法  
解：C  混淆矩阵只能用于分类模型，不能用于无监督学习。  
3. 下列哪个模型没有用到梯度？

   A. GradientBoost
   B. AdaBoost
   C. XGBoost  
解：B  

4. 正则化(regularization)的作用不包括以下哪个？

   A. 防止过拟合
   B. 去除噪点
   C. 降低模型复杂度  
解：B  
5. 卷积神经网络(Convolutional Neural Network)中通常包含卷积层和全链接层，它们的主要作用分别是

   A. 进行分类、提取特征
   B. 提取特征、进行分类
   C. 提取特征、提取特征  
解：B  
#卷10
1. 核空间的维度为n（rows）-r（秩）
2. 假设你对数据集中的某个特征x做非线性变换，人工建立4个新特征，生成方式分别是x2，x3，(x2+x)2，x4

。包括原特征在内的这5个特征是存在多重共线性(multicollinearity)问题？

   A. 没有
   B. 有
   C. 要看数据本身而论  
解：B  以x,x2,x3,x4为基，形成四维空间。但是有五个特征，必然存在线性相关组，即存在多重共线性。

#测试
1. 对于k近邻算法(k-NN)，当k=1时，下列哪个说法是合理的？

   A. 训练误差远小于预测误差
   B. 训练误差与预测误差接近
   C. 训练误差远大于预测误差  
解：A 1-NN会严重过拟合，训练误差为0，测试误差会比较大。  
2. 反复抛一枚硬币，直到抛出两次正面为止。我们期望要抛多少次？（默认这个硬币正反面的概率都是0.5）

   A. 4
   B. 5
   C. 6  
解：A 扔出一次正面，我们需要抛两次；由于每次实验之间是独立的，扔出k个正面，我们需要抛2k次；所以是4次。
另外一个思路是，正面和反面地位等价，出现两次正面也就等价于出现两次反面，所以2+2=4。
3. 甲、乙、丙三人去看了两场电影。
    甲对A电影的评分是3，对B电影的评分是4。
    乙对A电影的评分是5，对B电影的评分是3。
    丙对A电影的评分是4，对B电影的评分是5。
根据这三个人的评分，求电影A、B的余弦相似。

   A. 0.48
   B. 0.94
   C. 1.26  
解：B 即求两个向量的余弦。  
4. 有两组数据X和Y，已知Y=2X，（例如X={1,2,3,5,4}，Y={2,4,6,10,8}），那么X和Y
的相关系数是多少？

   A. 0
   B. 1
   C. 2  
解：B  完全正线性相关，所以相关系数为1  
5. 下面哪个集合不是凸集？

   A. {(x,y)|x−1>0,y>0}
   B. {(x,y)|x2+y2>1}
   C. {x|x>0}  
解： B  B是平面上抠掉一个圆，所以不是凸集。  

6. 对于基于决策树的xgboost模型，它的正则化是针对下列哪项？

   A. 树的个数
   B. 数据的平衡度
   C. 树的复杂度  
解：C  
7. 针对下面三种带有正则项的模型，哪个模型会保留更少的特征？

   A. LASSO
   B. Ridge
   C. ElasticNet  
解：A  LASSO可以将特征系数化为0，其他两者则较难做到。（http://sofasofa.io/forum_main_post.php?postid=1001156 ）  多重共线性  
8. 我们在下面的二元标签的数据集上训练一个线性SVM模型
    +：(−1,1),(1,−1),(−1,−1)
    −：(1,1),(2,0),(2,1)
这个模型中的支持向量是哪些？

   A. (−1,1),(1,1),(2,1)
   B. (−1,1),(−1,−1),(2,1)
   C. (−1,1),(1,−1),(1,1),(2,0)  
解：C  
9. 在神经网络中常用的激活函数中，下列哪个函数可以返回负数？

   A. ReLU
   B. Sigmoid
   C. tanh  
解;C  ReLU将负数映射为0。Sigmoid返回值在0到1之间。tanh返回值在-1到1之间。  
10. 给定一组样本，我们想通过T检验验证其总体均值的取值。已知单侧T检验的p值是α
，那么同样的情形下，双侧T检验的p值是多少？

   A. 2α
   B. α/2
   C. 以上都不对  
解：C  

#卷11
1. 已知A,B两个独立事件，如果P(A)=P(B),P(A∩B)=1，那么P(A)=？
   A. 0.5
   B. 1
   C. 无法确定  
解答： 答案是B。因为A,B独立，所以P(A∩B)=P(A)P(B)=P(A)2=1，所以选B。 
2. 今天下雨的概率为0.5，今天明天都下雨的概率为0.4。若今天下雨，明天不下雨的概率为？

   A. 0.5
   B. 0.8
   C. 0.2  
解答：今天下雨为事件A，明天下雨为事件B。 P(B|A)=P(AB)/P(A)=0.4/0.5=0.8。所以P(¬B|A)=0.2。  

3. 一个篮球运动员练习投篮200次，投进的次数不能用以下哪个分布近似？

   A. 二项分布
   B. 均匀分布
   C. 泊松分布  
解答：B， A和C均可以作为投篮计数模型。  
4. 已知三个独立变量X,Y,Z∼U(0,1)，那么min(X,Y,Z)

的期望是多少

   A. 1/3
   B. 1/4
   C. 1/6  
解答：B，1/（k+1） 
5. 如果之前四道题目（都是三选一的选择题），你都是蒙的，你有多大的把握可以答对其中至少1题？

   A. 65/81
   B. 3/4
   C. 80/81  
解答：答案为A。全错的概率为(2/3)4=16/81。

#卷12
1. 如果考虑对一个小样本（10个数据点）做总体均值是否大于0的假设检验，我们可以用

   A. Z检验
   B. T检验
  C. 两者都可以  
解答：B， 小样本时用T检验。  
2. 这组数据集(2,2,3,4,9)的中位数和众数分别是？
   A. 3, 2
   B. 3, 3
   C. 3, 4  
解：A  
3. 假设[a,b1]是总体A的均值的95%置信区间，[a,b2]是总体B的均值的90%置信区间，那么
   A. b1>b2
   B. b1≥b2
   C. 不确定  
解答：均值的置信区间的长度不仅与置信水平有关，还和样本方差有关。  
4. 在假设检验中，当我们错误地拒绝了原假设(零假设，null hypothesis)，这种错误被称作？

   A. 第一类型错误(Type I Error)
   B. 第二类型错误(Type II Error)
   C. 第三类型错误(Type III Error)  
解：A  
5. 显著水平(sigfinicance level)是指犯哪种错误的概率？
   A. 第一类型错误(Type I Error)
   B. 第二类型错误(Type II Error)
   C. 第三类型错误(Type III Error)  
解：A，在进行假设检验时提出原假设和备择假设，原假设实际上是正确的，但我们做出的决定是拒绝原假设，此类错误称为第一类错误。原假设实际上是不正确的，但是我们却做出了接受原假设的决定，此类错误称为第二类错误。  

#卷13
1. 两个二元分类模型A和B，我们使用同一个测试数据进行模型比较，下面说明正确的是
   A. A的logloss比B小，那么A的ROC AUC肯定比B小
   B. A的logloss比B小，那么A的ROC AUC肯定比B大
   C. 两者关系不确定  
解：C  
2. 对于非平衡数据集(imbalanced dataset)，下面处理方法不正确的是

   A. 对小数量的类(minor class)进行过采样（over sampling)
   B. 对大数量的类(major class)进行欠采样(down sampling)
   C. 对阳性样本和阴性分别训练模型  
解：C，过采样、欠采样都是处理非平衡数据的常用方法。  
3. 神经网络中隐藏层激活函数(activation function)的主要作用是

   A. 去除噪音
   B. 引入非线性变换
   C. 降低模型复杂度  
解答：激活函数的主要作用是引入非线性变换。  
4. 下面哪种聚类算法可以返回一个样本属于某一聚类的概率？

   A. 高斯混合模型(GMM)
   B. K Means
   C. 层次聚类(hierarchical clustering)  
解：A，硬聚类就是把数据确切地分到某一类中，比如K-Means。硬就是说“强硬”，是属于A类就是A类，不会跑到B类。
软聚类就是把数据以一定的概率分到各类中，比如高斯混合模型(GMM)，比如模糊C均值模型(Fuzzy c-Means)。聚类的结果往往是样本1在A类的概率是0.7，在B类的概率是0.3。软聚类又称为模糊聚类(fuzzy clustering）。  

5. 回归模型中存在两个特征具体多重线性(multi-colinearity)，可采取的做法是

   A. 将这两个特征删去
   B. 使用LASSO等方法，自己选择特征
   C. 都可以  
解答：可以删除其中一个或者用其他特征选择的方法。所以选B。  

#卷14
1. 在文本处理中，idf(逆向文件频率，inverse document frequency)是一个词语普遍重要性的度量。对于下面三段文本，
1: " Lucy loves dogs while Lily doesn't love dogs."
2: "There are many dogs in the park"
3: "Animals in the zoo are like people in the jail."
idf("dogs")等于多少？
   A. log(1.5)
   B. log(2)
   C. log(3)  
解：A，tf(w)=w出现在该文档的次数/该文档中总的词汇量
idf(w)=log(文档的总个数/包含w的文档的个数)
tf-idf(w)=tf(w)×idf(w)  

2. word2vec模型有几个隐藏层？

   A. 0
   B. 2
   C. 可以按照自己的需要设置隐藏层的个数  
解答：A，word2vec只有两层，即输入层与输出层，没有隐藏层。  
3. 对于n-gram模型，当n取值为多少时，这个n-gram相当于一个马尔可夫链（具有马氏性）？

   A. 1
   B. 2
   C. 3  
解：B，2-gram只考虑之前一个单词，即满足马尔可夫链的形式。  
4. CBOW(continuous bag of words)和skip-gram的目的分别是？

   A. 根据上下文预测词汇、根据词汇预测上下文
   B. 根据上下文预测词汇、根据上下文预测词汇
   C. 根据词汇预测上下文、根据上下文预测词汇
解：A  

5. 关于隐式狄利克雷分布模型(Latent Dirichlet Allocation, LDA)，下面说法正确的是？

   A. 有监督学习
   B. 无监督学习
   C. 增强学习  
解：B  

#卷15
1. 在用反向传播法(backpropagation)训练一个 10 层的神经网络时，你发现前 3 层的权重完全没有变化，而4，5，6 层的权重变化非常小，这个现象的原因可能是？

   A. 模型欠拟合
   B. 梯度消失
   C. 梯度爆炸  
解答：B，这个现象是典型的梯度消失。  
2. 下面哪种线性回归模型不具有鲁棒性(robustness)？

   A. 最小二乘回归(least squares regression)
   B. 分位数回归(quantile regression)
   C. Huber回归  
解：A，所谓鲁棒（robust），就是让模型本身尽量少受离群点的影响。  
3. 自编码器(autoencoder)的主要作用是什么？

   A. 聚类
   B. 降维
   C. 自动对分类特征(categorical feature)进行独热编码(one-hot encoding)  
解答：自编码器(autoencoder)是一种用于降维的神经网络。  

4. 随机森林是由很多棵随机决策树组成的，。从偏差方差权衡(bias-variance tradeoff)的角度来说，树的个数越多

   A. 方差越大
   B. 方差越小
   C. 偏差变小
   D. 偏差、方差都变小  
解：B，树的个数越多，偏差不变，方差变小。  
5. 下面哪种模型无法用神经网络的形式实现？

   A. Huber回归
   B. K近邻回归
   C. 逻辑回归  
解答：A和C本质上都是有不同目标函数的线性模型。而B无法用神经网络实现。  

#卷16
1. X,Y是独立的正态随机变量。X∼N(0,9),Y∼N(0,16)，那么Y−X服从什么正态分布

   A. N(0,7)
   B. N(0,1)
   C. N(0,25)
   D. N(0,49)  
解答：对于两个独立正太分布N(m1,σ21)+N(m2,σ22)=N(m1+m2,σ21+σ22)。所以选C。  
2. X是服从U(0,1)均匀分布的随机变量，求X2的期望。

   A. 1/2
   B. 1/3
   C. 1/4  
解答：Var(X)=E(X2)−E2(x)。所以E(X2)=Var(X)+E2(X)=1/12+1/4=1/3。当然也可以积分求解。  
3. 甲乙两个人比试射箭，两人射术水平一样，单次射中的概率都为 0.5。如果甲射了 201 箭，而乙射了 200 箭，求甲射中次数比乙射中次数多的概率是？

   A. 201/400
   B. 1/2
   C. 101/201  
解答：假设前两百次射完箭后，甲射中比乙多为事件A，乙射中比甲多为事件B，一样多为事件C。显然P(A)=P(B)，P(A)+P(B)+P(C)=1。甲射完第201箭之后，比乙射中多的概率为P(A)+0.5P(C)=0.5P(A)+0.5P(B)+0.5P(C)=0.5   
4. 已知一台服务器上玩家类型分布为， 人族：30%，兽族：15%，精灵族：50%，不死族：5%。任选一批玩家，希望他们中至少有一个是精灵族的可能性不低于 90%，那么最少需要选多少人?

   A. 3
   B. 4
   C. 5  
解答：假设x人，没有精灵族的概率为(1−0.5)^x。要使得0.5^x<0.1，x≥4。所以至少4人。 

5. 一个人患胃癌的概率为 1/1000。一台癌症诊断仪，如果患者确实患有胃癌，它的确诊率为 90%。如果患者没有喂癌，被诊断成癌症的概率是 10%。某人在被该仪器诊断为癌症后，他真正患癌症的概率为？

   A. 1/112
   B. 10/11
   C. 1/11   
解答：假设患癌为事件A，确诊为事件B。那么P(A)=1/1000，P(B|A)=0.9，P(B|¬A)=0.1。
P(A|B)=P(AB)/P(B)=P(B|A)P(A)/(P(B|A)P(A)+P(B|¬A)P(¬A))=0.9×0.0010.9×0.001+0.1×0.999=1112  

#卷17
1. 最小二乘线性回归的前提假设之一是要求误差具有等方差。如果误差不具有等方差性，那么最小二乘得到的回归系数的估计值将是

   A. 有偏差的(biased)，无效的(invalid)
   B. 无偏差的(unbiased)，无效的(invalid)
   C. 无偏差的(unbiased)，有效的(valid)  
解：B， 最小乘模型的无偏性不依赖于等方差误差的假设。但是如果违背了等方差性假设，这个估计是无效的。  
2. 一个二元分类器，输出一组预测样本为阳性的概率。我们以0.5为阈值，概率大于0.5则将该样本标记为+，小于等于0.5则标记为-。如果我们将这个阈值降低到0.4，那么

   A. 召回(recall)肯定变大
   B. 召回不变或者变大
   C. 召回可能变大也可能不变，也可能变小  
解：B，阈值降低，那么模型会标记出更多的阳性，所以真阳性可能变多或者不变。阳性样本总数不变。  
3. 逻辑回归的损失函数（不带正则项）是凸函数吗？

   A. 不是
   B. 是
   C. 与训练数据本身有关，通常是凸函数  
解答：是的。是凸函数。因为是凸函数，所以我们常常用SGD来求解。  
4. 随机森林是由很多棵“随机”决策树组成。“随机”的意思不包括

   A. 决策树随机选取样本
   B. 决策树随机选用特征
   C. 决策树随机选择最大深度  
解答：随机森林中的随机是针对选项A和B。而最大深度是剪枝的选项，通常是在训练前决定的，是随机森林的超参。  

5. 下列哪种训练方法不属于数据泄漏(data leakage)？

   A. 模型的目标是预测儿童成年后的身高。在训练集中我们用了爷爷奶奶的身高来预测父母身高。
   B. 模型的目标是在比赛开始前预测比分。在训练集中我们提取了足球比赛上半场的比分来预测下半场的比分。
   C. 模型的目标是预测信用卡欺诈消费。在训练中，由于数据是严重非平衡的(imbalanced)，我们从验证集中复制部分数据到训练集中，使正负样本平衡，从而提高了模型准确率。  
解答：A，选项B使用了未来的信息，因为我们需要在开赛前预测比分，而不是在半场之后。选项C使用了验证集的数据来训练模型，属于“作弊”。

#卷18
1. 一个网上授课网站，为了改善支付页面的布局，对当前版本和实验版本进行A/B Test，实验长度为两周。下面哪个度量可以有效反应出改版的成效？

   A. 不同版本下课程订购次数
   B. 不同版本下学生的结课率
   C. 不同版本下网站课程流量  
解答：A， A/B Test是一种极具针对性的对比方式。B和C没有针对“支付”。  
2. 在一次实验中，10000个新用户当中有1000个用户进行了付费升级，升级率为10%。而过去的总升级率只有5%。过了一周，决定重复这次实验，有10000个新用户参加这个实验，在其他条件都几乎相同的情况下，下面哪个结果会让人感到意外？

   A. 这次实验的升级率为10.3%
   B. 这次实验的升级率为11.5%
   C. 这次实验的升级率为9.8%  
解答：B，有时候为了确保A/B Test的实验结果有效，会间隔一段时间在尽量一样的条件下重新测试一次。此时我们希望能重复之前的结果。在升级率为10%，人数为10000人时，均值估计的标准误(standard error)是0.3%。根据3σ原则，超过0.9%是可能性非常非常小的，所以B会很让人意外。  
3. 下面哪项任务无法由A/B Test参与完成？

   A. 改进商品推荐算法
   B.收集用户的反馈意见
   C. 调整网站页面布局  
解答：B， A和C都是A/B Test的经典应用。B一般通过抽样问卷调查完成。  
4. A/B Test中A代表对照组(control)，B代表实验组(test)。为了使实验有效，A和B的样本数量必须要相等或者几乎相等？

   A. 是的
   B. 不是  
解答：没必要50对50进行A/B Test。现实中，如果总样本数量巨大（比如流量很大的网站），考虑到新版本(B版本)中的不确定性，通常将B版本只在少量的样本上实验，如5%,10%，以免造成巨大损失。  
5. 我们对A/B Test中B版本中某个按钮的点击率做分析。实验组中共有10000次点击，点击率为a1，约为5%，我们得到该按钮的点击率的95%置信区间，该置信区间的长度为l1。若后来又进行了一次A/B Test，此次实验组中共有10000次点击，点击率降低为a2，那么这次点击率的95%置信区间的长度l2和l1的关系是？

   A. l1>l2
   B. l1<l2
   C. 无法判断，要根据真实数据而论  
解：A， 解答：95%置信区间的长度是
l=2×1.96×SE.
第一次实验的标准误
SE1=sqrt（a1(1−a1)/10000）
第二次实验的标准误
SE2=sqrt（a2(1−a2)/10000）
因为a2<a1<0.5，所以SE2<SE1。所以l1>l2。

#卷19
1. 关于线性空间，下面说法正确的是？

   A. 线性空间一定包含零元（零向量、零点）
   B. 线性空间有且只有一组正交基
   C. 线性空间的维数要么是1要么是正无穷  
解答：A， 线性空间可以有无数组正交基。线性空间的维数可以说任意非负整数。  
2. 对于一个m×n的矩阵，假设它的秩(rank)为R，下列不等式最准确的是？

   A. R≤max(m,n)

   B. R≤min(m,n)
   C. R≤m  
解答：秩不超过列数、不超过行数。  
3. 对于两个n×n矩阵A和B，正常情况下（不考虑大数的加乘），计算AB

的时间代价是

   A. O(n^2)
   B. O(n^3)
   C. O(n^4)  
解答：B,每个元素的计算量为O(n)，矩阵共有n^2个元素。  
4. 这三个向量
a=(1,0,0), b=(1,1,0), c=(1,1,1)

线性相关吗？

   A. 相关
   B. 不相关  
解：B  
5. 一个n×p的矩阵M，其中每一行代表一个样本，每一列代表一个特征。用SVD对M进行分解，截取主要成分(PCA)，我们可以得到M≈PΣQT，其中Σ是对角阵。下面哪个选项可作为M

的降维后的矩阵？

   A. PΣ
   B. ΣQT
   C. Σ  
解：A  

#卷20
1. 如果一个事件发生的概率为0，那么这个事件

   A. 依然有可能发生
   B. 一定不可能发生  
解答：A， 尽管概率为0，却依然有可能发生。例如，一个服从标准正态分布的随机变量等于0的概率为0。
2. 抛一枚硬币，正面朝上的概率为α。如果抛三次硬币，得到的结果分别是正面(H)，反面(T)，正面(H)。那么似然函数(likelihood function) L(α|HTH)等于

   A. α
   B. α^2−α^3
   C. 2/3  
解答：B,L(α|HTH)=Pα(HTH)=α(1−α)α=α^2−α^3。
选项C是α的最大似然估计。可对上式求导得到。  
3. 甲罐子里有1个红球，4个黑球；乙罐子里有3个红球，2个黑球。小明从某个罐子里拿出一个球，发现是红球，这个球是从甲罐子里取出来的概率是多大？

   A. 0.1
   B. 0.25
   C. 0.4  
解：B  
4. 卫生组织去街头调查某城市有多少人吸过毒。为了保护受访者隐私，每个受访者从一个装有2个红球3个黑球的袋子里随机摸出一个球。
如受访者摸到红球，则回答“ 问题1：你的生日是在1到6月份吗？”
如受访者摸到黑球，则回答“ 问题2：你吸过毒吗？”
采访者不知道受访者摸到的球的颜色，也就是说采访者并不知道受访者回答的是问题1还是问题2。一共2000人受访，460人回答“是”。请估算该城市的吸毒率。

   A. 4%
   B. 4.6%
   C. 5%
   D. 6%  
解：C，这个例子是著名的敏感性调查。2000个人中期望有800人摸到红球，他们生日在1到6月的概率为0.5，所以我们期望有400个“是”来自于问题1。剩下的60个“是”来自于1200个问题2，所以60/1200=5%。
当然，本题也可以用贝叶斯公式求解。  
5. 一个取值范围为[0,1]的连续随机变量，它的概率密度函数(pdf)为f(x)=ax，那么a=

   A. 2
   B. 1
   C. 1/2  
解：A，∫axdx=a2=1所以a=2。

#卷21
1. 我们在一个二元分类的数据集上训练线性SVM，其中阳性样本的坐标分别是(0,−1),(0,0),(0,1),(0,2),(1,0),(1,1)。如果我们去掉(0,1)这个点，重新训练模型，得到的新的支持向量和原来的相同吗？

   A. 不一定
   B. 相同
   C. 一定不同  
解：A  

2. 已知一个数据集，有自变量X1
，X2和X3以及数值因变量Y，我们用它们对Y做最小二乘线性回归(OLS)，得到R2，数值记为a1。其他条件不变的情况，去掉变量X3，只用X1和X2，此时得到的R2，记为a2。关于a1和a2大小关系说法正确的是？

   A. a1≤a2
   B. a1≥a2
   C. 两者关系不确定，视数据本身而定。  
解答：B，对于OLS来说，更多的变量总能使得拟合度(R2)提高。如果从优化的角度来说，去掉变量X3，相当于强制X3的系数为0。这种情况下的最优解对应的R2肯定会小于之前的R2。  

3. 下面哪种神经网模型，一般不存在权值共享的情况(shared weights)？

   A. 递归神经网络(RNN)
   B.多层感知机模型(MLP)
   C. 卷积神经网络(CNN)  
解：B  

4. 如果一个二元分类模型在训练集上召回(recall)是1，在测试集上的召回也是1，那么说明这个模型一定很好。

   A. 是的
   B. 不是  
解：B，在评价模型时，召回是一个重要参考，但是往往需要结合其他度量，比如精度。最极端的情况是，一个模型总是把任何样本都标记为1，这样无论什么情况，召回永远是1。  
5. 某网站对所有注册用户的真实姓名发现，如果名字里含有“艺”那么0.6的概率为女生；名字里含有“兴”那么0.8
的概率为男生。如果我们用朴素贝叶斯做分类器， “艺兴”是男生的概率为？

   A. 条件不足无法计算
   B. 0.60
   C. 0.57  
解：A  

#卷22
1. 从一个均匀分布U(0,x)中随机抽出了5个数，分别是1.2,3.3,1.9,0.5,1.8，那么x的最大似然估计(MLE)为

   A. 3.3
   B. 4
   C. 3  
解答： 似然函数
L(x)=1/x^5
x的取值范围为[3.3,∞)，所以最大似然估计为3.3。  

2. 小明和小刚玩骰子。小明扔两次骰子，将两次的数字相乘；小刚扔一次骰子，将得到数字取平方。谁的结果大，谁就赢。你觉得谁的胜算大？

   A. 小明
   B. 小刚
   C. 一样大  
解答：B,最直接的方法是把所有情况枚举出来。比较聪明的方法是利用方差的公式来计算。小明扔了两次，可以看作E[X1]E[X2]，因为X1与X2独立同分布，所以E[X1]E[X2]=(E[X1])^2=E[X1^2]−Var[X1]
方差非负，所以E[X1^2]>E[X1]E[X2]。  

3. 连续抛一枚公平的硬币，直到连续出现两次正面为止，平均要扔多少次硬币？

   A. 4
   B. 6
   C. 8  
解：B，参考(http://sofasofa.io/forum_main_post.php?postid=1001963)  
4. 假设98%的注册用户都在某电商平台上有过消费，但是大部分人的消费额不高，整体上成长尾分布(long-tailed distribution)，那么关于中位数与平均数，你觉得正确的是

   A. 消费额的中位数大于平均数
   B. 消费额的中位数小于平均数  
解：B，B为长尾分布的基本特征。可画出直方图来分析判断。  
5. 甲、乙两支篮球队进行比赛，采取七场四胜制。每场比赛甲赢的概率都是0.5，求他们要打满7场才能决定胜负的概率是多少。

   A. 5/16
   B. 3/8
   C. 9/32  
解：A，要打满7场，意味着前6场必须各赢三场，也就是C（6，3）*（1/2）^6  

#卷23
1. 假如矩阵A的行列式|A|=1，那么|A−1|等于

   A. 1
   B. −1
   C. 确定因为A不一定可逆  
解：A。首先A一定可逆，如果A不可逆，那么|A|的行列式为0。其次1=|I|=|A−1A|=|A||A−1|。所以|A−1|=1。  
2. 一个数据集中有n个样本，每个样本有k个数值特征，整体可以看作一个n×k的矩阵D。现在设计一个k×p的矩阵M，其中k<p<n，用来人工合成新的特征，新的数据集DM有p个特征，所以M起到升维的作用。那么新数据集DM中存在多重共线性问题吗？

   A. 不存在
   B. 存在
   C. 要看数据本身包括原数据是否存在多重共线性  
解：B。肯定存在多重共线性，因为这p个特征是原本k个特征的线性组合。所以这种“升维”方式并不可靠。  
3. A是一个n×n的矩阵，v是一个n×1的列向量，（在不考虑稀疏和大数乘法加法的情况下，）得到Av的计算量为

   A. O(n)
   B. O(n^2)
   C. O(n^3)  
解：B。Av的结果是一个高度为n的列向量，其中每个元素需要经过O(n)次运算。所以计算量为O(n^2)。  
4. 对于一个给定的矩阵A，若已知它其中一个特征值λ，那么存在唯一的向量v使得Av=λv。

   A. 正确
   B. 错误  
解答：B。对于任何非零常数c，向量u=cv也是A关于特征值λ的特征向量。所以不唯一。  
5. 假设有如下函数
f(x1,x2)=(x1−2)2+(x2−4)2+(x1+x2)2,
该函数在(2,4)

的梯度为？

   A. (12,12)T
   B. (2,4)T
   C. 36  
解：A  

#卷24
查看维基百科皮尔逊系数

#卷25
1. 下列哪种结构更适用于时间序列的数据？

   A. Recurrent Neural Nets
   B. Convultional Neural Nets
   C. Multi Layer Preceptron  
解：A  
2. 神经网络中常用的Batch Normalization(批标准化)作用在

   A. 输入前的数据预处理
   B. 神经层与层之间的数据
   C. 输出层的结果  
解答：正常的normalization是在数据进入模型前的预处理，而batch normalization是对层与层之间的数据进行标准化，然后再输入激活函数。  
3. 如果直接对一个1024\*1024的图片做max pooling，pooling参数为
kernal_size=8*8，padding=0，stride=8
pooling后的图片尺寸为

   A. 256\*256
   B. 128\*128
   C. 8\*8  
解答：B。每个kernal提取一个信息点，stride=8，所以kernal之间没有重叠。一共128*128个kernal。
4. dropout常用于防止神经网络过拟合，在训练时会随机删去一些神经节点。

   A. 在测试验证时，我们也需要随机去掉一些神经节点
   B. 在测试验证时，我们不需要随机去掉一些神经节点  
解：B。在进行测试验证时，我们需要保留完整的网络结构。  
5. 对于一个只有一个隐藏层的全连接前馈神经网络，如果输入层是10个节点，隐藏层是20个节点，输出层是2个节点。整个网络中有多少个权值需要被计算？

   A. 240
   B. 400
   C. 32  
解：A。输入层和隐藏层之间有10*20=200条边。隐藏层和输出层之间有40条边。每个边有一个权值，所以是240个。

#卷26
1. 在招聘过程中，接到面试邀请的人当中，有20%能通过第一轮面试、进入第二轮面试。通过第一轮的求职者中，有90%觉得自己第一轮的确面得不错。然而在没有通过第一轮面试的人当中，也有50%的人也觉得自己在第一轮面得不错。
如果你觉得你第一轮面得不错，你进入下一轮面试的概率是多少？

   A. 0.31
   B. 0.22
   C. 0.18  
解：A。 这是一道求解条件概率的题目。假设第一轮感觉不错为事件A，通过第一轮为事件B，我们要求的是P(B|A)。已知条件有P(B)=0.2，P(A|B)=0.9，P(A|¬B)=0.5。
P(B|A)=P(A|B)P(B)/P(A)=P(A|B)P(B)/P(A|B)P(B)+P(A|¬B)P(¬B)=0.9×0.20.9×0.2+0.5×0.8≈0.31.
这个题目告诉你，即使你感觉不错，你通过面试的概率依然不“那么”大。  

2. U(a,b)表示[a,b]上的均匀分布。如果X∼U(−1,1)，Y∼U(−1,1)并且X和Y独立，求条件概率P(X+Y>1|X>0)

   A. 1/3
   B. 1/4
   C. 1/8  
解答：常规做法是利用条件概率的公式分布求解。
P(X+Y>1|X>0)=P(X+Y>1,X>0)/P(X>0)=∫1,0 1/2∫1,1−x 1/2dydx/(1/2)=14.
另一种对于均匀分布的常用方法是作图法，在坐标系中画出Y=1−X，图线右上方的面积占X=0右侧的面积的1/4，所以答案是B。  

3. 将“g”，“o”，“o”，“g”，“l”，“e”这六个字符任意打乱顺序，重新排列，可以得到多少个不同的字符串

   A. 720
   B. 180
   C. 32  
解答：如果是六个完全不同的字符，那么重排列的个数是6!。而此处有两个“g”，两个“o”，所以总个数为
6!2!2!=720/4=180.  
4. 两样本T test可以用来检验

   A. 两个样本的均值是否相同
   B. 两个总体的均值是否相同  
解答：B.基本概念。样本均值是已知的，我们希望通过样本来估计和判断总体的均值是否相等。  
5. 有5个会议室，分别为会议室1、会议室2、……会议室5，与此同时，有三个会议要同时被安排。假定会议被安排的会议室是随机且独立的，已知至少有一个会议被安排在了会议室1，那么会议室1有几个会议（期望）？

   A. 75/61
   B. 8/5
   C. 7/5  
假设N个会议室，k个会议，假设X个会议被安排在了会议室1，我们要求解的是E(X|X≥1)。很显然
E(X)=E(X|X≥1)P(X≥1)+E(X|X=0)P(X=0)=E(X|X≥1)P(X≥1).
很容易求得
P(X≥1)=1−((N−1)/N)^k
以及
E(X)=k/N.
将k=3以及N=5代入上面的式子，就可以求得结果。  

#卷27
1. 对于一组二元分类任务的测试集，其真实值为[0, 0, 0, 0, 1, 1, 1]，模型预测为1的概率为[0.3, 0.2, 0.7, 0.5, 0.4, 0.9, 0.6]，该模型在这个测试集上的ROC曲线为

   A.
   B.
   C. 
解：A  
2. “近朱者赤、近墨者黑”与下面哪个算法是类似的思想？

   A. k-Means
   B. k-Nearest Neighbors
   C. Decision Tree  
解：B 相近的点有一样的标签，所以是k-NN模型。  
3. 假如你有一个很大的训练集，而且你当前的首要考虑是训练速度，那么下面哪种正则化手段最不应该考虑？

   A. L1
   B. L0
   C. L2  
解：B，这三种正则项都能起到约束模型的作用。L0是指模型中非零参数的个数。在优化中，它没有显示的数学表达，能准确地说，含有L0正则项的优化问题是一个离散优化问题，而且是NP Hard。  
4. 训练单个决策树是肯定无法进行并行化的。这个说法对吗？

   A. 正确
   B. 错误  
解：B，即使是单个决策树也是可以进行并行化的。因为每个树杈的分裂点选择上，我们需要遍历所有的特征。这个步骤是可以被并行的  
5. XGBoost与GradientBoost的不同之处不包括

   A. XGBoost使用了更复杂的决策树结构
   B. XGBoost将树的复杂度加入到了损失函数中作为惩罚项
   C. XGBoost使用了二阶导数  
解：A，不包括A；相反的是，XGBoost想控制（降低）树的复杂度。  

#卷28
1. 某电商网站准备上线新的商品推荐算法，他们想先进行A/B Test试试效果如何。下面哪种metric不适合用来度量这次A/B Test？

   A. 浏览网站的人数
   B. 人均商品的点击次数
   C. 人均交易金额  
解答： A，好的推荐算法可以增加点击量、增加购买量。在做A/B Test的时候实验组和对照组的人数是相对固定的。  
2. 在A/B test试验一个新版本页面，新版本有一百万个订单，其中退单个数为一万个。我们估计退单率为1%。这个估计值的标准差约为？

   A. 0.1%
   B. 0.01%
   C. 0.001%  
解答： B,这个估计值就是均值，我们知道均值估计值的标准差为
sqrt(σ^2/n)
此问题的σ2=0.01×0.99≈0.01，所以估计值的标准差为
sqrt(0.01/10000)=0.0001=0.01%  
3. 某咨询公司建议电商网站更新网站的UI，并通过A/B Test的方式，找到最能拉动回头客的UI。这项建议不适合以下哪类电商平台？

   A. 书籍电商
   B. 二手车电商
   C. 零食电商  
解答：B,A/B Test的时长通常在1周到3个月之间，而买车的需求量通常两年内才一次。  
4. 只有网站流量足够大，A/B Test的实验时间短点（比如一天或者两天）也没关系。这个说法对吗？

   A. 正确
   B. 错误  
解答：B,A/B Test通常会以周为单位，因为很多网站受到星期周期的影响，此次在设计实验时并不清楚实验和周末、非周末的关系。一般不建议短于7天的A/B Test。
5. AA Test的目的不包括以下哪项？

   A. 节约时间、加快整个Test的进程
   B. 确保整个测试系统无误和随机性
   C. 观测metrics的方差和波动性  
解答：A,AA Test是指对照组和实验组一样。通常是在AB Test开始前进行，确保整个测试系统无误，确保流量/人群按照实验目的进行随机划分，此外还能观测到metrics的方差和波动性。有时候，AA Test会在AB Test再进行一次，以确保AB Test的结果具有说服性。

#卷29
1. C是SVM中的惩罚系数，C越大，

   A. 模型越容易过拟合
   B. 模型泛化能力越强
   C. 模型越容易欠拟合  
解答： A，SVM中C是惩罚系数，即对误差的宽容度。C越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差  

2. 在线性回归中，R2常用来表示拟合度。假如有三个样本，真实值分别为10，15，20，拟合值分别为12，15，19。求R2。

   A. 0.85
   B. 0.90
   C. 0.95  
解答：
R2=1−SSE/SST=1−(10−12)2+(15−15)2+(20−19)2(10−15)2+(15−15)2+(20−15)2=0.90  

3. 对于PCA说法错误的是：

   A. 我们可以利用PCA降维来完成数据可视化
   B. 我们应该选择有最小variance的成分
   C. 我们在使用PCA前需要规范化数据  
解答：B，B选项说反了，应该是选择variance最大的成分。  

4. Adaboost有很多决策树组成。树与树是相互独立的吗？

   A. 是
   B. 不是  
解答：B，Random Forest中的树是相互独立的，boosting中的树不是独立的（包括Adaboost，GradientBoost等等）。  

5. 时间序列模型ARIMA包含三个部分，自回归（AR），差分（I），移动平均（MA），其中哪个部分能够使时间序列稳定（stationary）？

   A. I
   B. MA
   C. AR  
解答：A，I的作用是把一个non-stationary的时间序列转化为stationary的时间序列。

#卷30
1. 小王和小张通过反复抛一枚硬币来玩一场游戏。这个硬币是无偏的，也就是说出现正面(H)和反面(T)的概率都是0.5。在反复抛硬币的过程中，如果先出现了HTH，则小张获胜；若先出现HHT，则小王获胜。求小王获胜的概率。

   A. 2/3
   B. 1/2
   C. 1/3  
解：A.解答： 假设小王赢的概率为p。
若第一次扔的是T，那对比赛进程没有任何影响。所以第一次扔出是T并且小王获胜的概率为p/2。
若第一次扔出H，第二次扔出的结果仍然是H，那么小王一定会获胜（想想为什么）。所以第一、二次扔出的是HH并且小王获胜的概率是1/4。
若第一次扔出H、第二次扔出T、第三次扔出H，则小张获胜。
若第一次扔出H、第二次扔出T、第三次扔出T，则相当于比赛重新开始。所以前三次扔出HTT并且小王最终获胜的概率为p/8。
最终我们可得
p=p/2+1/4+p/8
解得p=2/3。  

2. 正态随机变量X∼N(a,9)，正态随机变量Y∼N(b,4)，求以下的协方差cov(X−Y,X+Y)。

   A. 1
   B. 5
   C. 均值和相关系数未知，无法求解  
解答： 协方差的计算公式为

cov(X−Y,X+Y)=E((X−Y)(X+Y))−E(X−Y)E(X+Y)
可进一步化简可得

E((X−Y)(X+Y))=E(X^2−Y^2)=EX^2−EY^2
以及

E(X−Y)E(X+Y)=(E(X)−E(Y))(E(X)+E(Y))=E^2 X−E^2 Y

最后可以得到

cov(X−Y,X+Y)=EX^2−E^2 X−(EY^2−E^2 Y)=var(X)−var(Y)=9−4=5  
3. 抽屉里有4个骰子，一个4面骰子，两个6面骰子，一个12面骰子。假设这些骰子都是公平的。小王从抽屉里随机拿出一个骰子，扔出来的结果是4的概率是多大？

   A. 1/4
   B. 1/6
   C. 1/7  
解答：B，1/4(1/4+2*1/6+1/12)=16

4. 已知两个取值范围为[0,1]×[0,1]
的随机变量X,Y的联合密度函数为12x^2 y^3。X和Y
是独立的吗？

   A. 不独立
   B. 独立  
解：B。解答：X的边际密度函数是
fX(x)=∫<sup>1</sup><sub>0</sub>12x^2y^3dy=3x^3
而Y的边际密度函数是
fY(y)=∫<sup>1</sup><sub>0</sub>12x^2 y^3dx=4y^3
两个密度函数都只涉及本身的那个变量，所以独立。  

5. 抽屉里有4个骰子，一个4面骰子，两个6面骰子，一个12面骰子。假设这些骰子都是公平的。小王从抽屉里随便拿一个骰子，扔出来的结果是4。那么用这个骰子再仍一次，扔出的结果是大于4的概率是多大？

   A. 1/4
   B. 1/3
   C. 1/2  
解答：A,这个题目是第三题的延续。4面骰、6面骰、6面骰、12面筛的先验概率为1/4,1/4,1/4,1/4。在扔出4之后，后验概率为3/8,1/4,1/4,1/8(即扔出4的骰子是4面骰，6面，6面，12面的条件概率)。每个骰子扔出大于4的数的概率分别为0,2/6,2/6,8/12。所以最后结果为
3/8×0+1/4×2/6+1/4×2/6+1/8×8/12=1/4
如果第一次扔出来的数字是5，那么第二次扔出大于5的概率是多大呢？  

#卷31
1. 已知x1=1,x2=2,x3=4,x4=8,x5=10，求y使得
∑<sub>i</sub><sup>5</sup>=|y−x<sub>i</sub>|达到最小值。
   A. 4
   B. 5
   C. 都不对  
解答：A, y应该是所有数的中位数。类比于中位数回归（最小均值）。  

2. 在一个二元分类的预测任务中，真实标签为0,0,0,0,1,1,1,1,1,1
，预测值为0,1,0,1,0,1,1,1,0,1

。那么这个预测结果的灵敏度(Sensitivity)和特异度（Specificity）分别是多少？

   A. 2/3，1/3
   B. 2/3， 1/2
   C. 3/4，1/3  
解：Sensitivity也是真阳性率（召回、回测），Specificity也是真阴性率。答案为
4/6=2/3
以及
2/4=1/2

4. 下面哪种算法可以用来实现高斯混合模型(GMM)

   A. SGD
   B. EM  
解答：B,一般用EM实现GMM。  
5. 一个二元逻辑回归模型具有如下的决策边界x1+x2-1=0，那么这个逻辑回归的表达式可以为
p(Y=1|X)=e^(x1+x2−1)/(1+e^(x1+x2−1))
或p(Y=0|X)=1/(1+e^(x1+x2−1))

#卷32
1. 现在准备做一个双样本独立T检验(two-sample unpaired T test)，这两个样本各有20个数据点，假设两个总体方差相等，那么这个T检验的自由度(d.o.f.)是多少？

   A. 38
   B. 18
   C. 19  
解答： A，双样本独立T检验的自由度为(n1−1)+(n2−1)，所以这里是38。  

2. 已知X,Y独立并且分别服从不同的均匀分布。X∼U(0,2)以及Y∼U(1,3)。求max(X,Y)
的期望。

   A. 25/12
   B. 49/24
   C. 9/4  
解答： B，相当于是求解如下积分
∫<sup>3</sup><sub>1</sub>∫<sup>2</sup><sub>0</sub>y/4dxdy−∫<sup>2</sup><sub>1</sub>∫<sup>x</sup><sub>1</sub>y/4dydx+∫<sup>2</sup><sub>1</sub>∫<sup>2</sup><sub>y</sub>x/4dxdy  
3. 假设今天下雨的概率是0.2，你在考虑带或不带伞。为了评估影响，选择策略，你设计了如下损失函数：
如果淋雨，记4分
如果带伞却没下雨，记2分
如果带了伞并且下雨，记1分
如果没带伞，也没下雨，也记录一分。
为了让影响尽量小（损失函数尽量小），带伞的最佳策略是？

   A. 带伞
   B. 不带伞
   C. 以0.4的概率带伞  
解答：B ,假设我们带伞的概率为p。那么损失函数为
cost=4×0.2×(1−p)+2×0.8×p+1×0.8×p+1×0.2×(1−p).
当p=0时，损失函数达到最小值。所以不带伞。  
4. 在假设检验中，alpha是指犯下列哪类错误的几率？

   A. 第二类错误Type II error
   B. 第一类错误Type I error  
解：B，alpha是第一类错误，beta是第二类错误。  

5. 在一个赌场里，机器为游客随机从1，2，3到100中挑一个数，若选出来的数是k
，一个公平的硬币就要被抛k

次。如果最终硬币只恰好出现了一次正面朝上，就算该游客获胜。求该游客获胜的概率（可近似、不需要使用编程或者计算器）。

   A. 0.02
   B. 0.05
   C. 0.1  
解答：获胜的概率p为
p=1/100∑<sub>k=1</sub><sup>100</sup> k/2^k
也就是
100p=1/2+2\*1/2^2+3\*12^3+4\*1/2^4+⋯
等式两边同时乘以1/2，可得
50p=0+1\*1/2^2+2\*1/2^3+3\*1/2^4+⋯
两个式子相减得到
50p=1/2+1/2^2+1/2^3+1/2^4+⋯
显然右边的和近似为1，所以p=0.02。  

#卷33
1. 两个独立的均匀分布的随机变量X1,X2∼U(0,1)，求max(X1,X2)−min(X1,X2)

的期望

   A. 1/3
   B. 1/6
   C. 1/9  
解：A， 等价于求解一个二重积分
2∫10∫1x1(X2−X1)dX2dX1
最终结果为1/3。  
2. 我们从一个有100000条样本的数据库中，有放回地随机抽取100000条样本。原数据库中大约有百分几的样本没有被抽中？

   A. 50%
   B. 37%
   C. 0%  
解：B，（http://sofasofa.io/forum_main_post.php?postid=1000691 ）

#卷34

#卷35
2.（http://sofasofa.io/forum_main_post.php?postid=1001461 ）
#卷36

#卷37

#卷38

#卷39

1. 什么是维度灾难(curse of dimensionality)？
维度灾难会带来什么麻烦？  
解：简单来说，由于数据维度过高（特征太多）造成的问题就是维度灾难。

维度灾难带来的问题包括：需要大量的空间来存储数据；计算复杂度过大，造成运算过慢；特征中会存在多重共线性；数据会有稀疏性。
例如：基于距离的算法比如kNN和kMeans都对高维数据很敏感，而且计算量很大；线性模型对多重共线性数据非常敏感，因为无法求逆。   
2. 
生成模型(generative model)和判别模型(discriminative model)的区别是什么?
举出一些生成模型的例子以及判别模型的例子。   
解：生成模型关心的是数据和结果的生成方式；换句话说，生成模型是通过数据学习得到特征和结果的联合分布f(X,y)，然后再通过联合分布得到最终的预测结果
判别模型并不关心数据是如何生成的，而是直接去判断对于给定的数据，哪一种结果可能性更大；换句话说，判别模型试图去学习argmaxyP(y|X)。

生成模型包括朴素贝叶斯、线性判别分析(linear discriminant analysis)、隐式马尔可夫模型(HMM)、生成对抗网络(GAN)、高斯混模型(GMM)等；判别模型包括逻辑回归、支持向量机、决策树、随机森林、boosting、前馈神经网络等。  
3. 非监督式学习也会过拟合(overfitting)吗？请举个例子。   
非监督式学习也是会有可能发生过拟合现象的。
非监督式学习中的两个主要用途是无监督降维和聚类。自编码器（autoencoder）就是一个常用的降维方法，当输出层的结果和原结果非常接近时，就很可能已经发生过拟合了，导致自编码器的泛化能力下降；K Means是常用的聚类算法，当k选取过大时，也可能会发生过拟合。（http://sofasofa.io/forum_main_post.php?postid=1001398 ） （http://sofasofa.io/forum_main_post.php?postid=1000490 ）  
4.  对数据进行标准化之后，线性回归模型有没有受到影响？Ridge回归模型有没有受到影响？  
解：线性回归模型不会受到数据标准化的影响。Ridge会受到影响，因为在目标函数含有正则项
∥β∥<sup>2</sup><sub>2</sub>
标准化前后的回归系数大小不同，也就直接影响到了正则项的大小。 另外值得注意的是，如果用梯度下降等算法求解线性回归，即使是否标准化对最终模型系数没有影响，但是会影响到优化算法的收敛速度。(http://sofasofa.io/forum_main_post.php?postid=1001740)  
5. 
在模型进行调参时，往往需要借助模型验证，交叉验证(k-fold cross-validation)和划分训练集、测试集的验证(train-test split validation)相比有什么优势？
k折交叉验证的中k的选取有什么注意事项？  
解：做k-fold的cross-validation时，每个样本都会有k-1次作为训练集，而1次作为验证集。而划分训练集、测试集的验证方法并没有充分利用数据，因为有的数据只参与了训练、有的只参与了验证。


#卷40

#卷41
1. XGBoost和GradientBoost的区别是什么？
XGBoost的基分类器只能是树吗？如果基分类器是线性分类器会是怎么样？  
解：XGBoost中XG是eXtra Gradient的缩写，有极致梯度的意思。它相比于GradientBoost，有两个明显的不同，一是xgb利用了损失函数的二阶导数，而传统的GBDT使用了一阶导数；二是XGBoost引入了正则项，防止过拟合。此外XGBoost与GBDT的不同还包括：
   1. 特征抽样(feature subsampling)。xgboost借鉴了随机森林的做法，在树每次分叉时只考虑一部分特征，不仅能降低过拟合，还能减少计算。
   2. XGBoost支持并行。XGBoost的并行是在特征粒度上的，也就是每次分叉选择特征时。
   3. 可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以XGBoost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。

XGBoost也支持线性分类器。如果基分类器不是决策树，而是线性分类器的话，这个时候XGBoost相当于带L1和L2正则化项的逻辑回归。

拓展：xgboost的gblinear是什么意思？  
因为对于线性回归来说，stack是没有意义的，这里的gblinear的意思实际上就是用sgd的迭代方法来训练一个LASSO线性模型。此时基于gblinear的xgboost就没有真正的‘boost’，只是一个用sgd求解的普通线性模型。  
2. 如何用牛顿法近似求解x3−6x在x∈(0,∞)上的最小值?给出迭代步骤。   
拓展：为什么机器学习中的优化问题很少用到牛顿法？  
牛顿法需要计算二阶导数，也就是说要计算一个Hessian矩阵。

    有些时候，损失函数的二阶导数的显式方程未必那么好求。机器学习不同于传统的优化问题，前者的目标函数可能是自己的定义的，未必是光滑的。
    机器学习问题与传统优化的另外一个区别是，前者的维数通常会很大，经常会上百或者上千乃至上万。如果数据集有n个特征，那么这个Hessian矩阵就是n x n的，我们需要求n平方个点，而sgd只需要求n个点。
    当n很大的时候，我们需要存一个n x n的矩阵，在空间也会是一个负担。

其次，牛顿法的步长是通过导数计算而来的。所以当临近鞍点的时候，步长会变得越来越小，这样牛顿法就很容易陷入鞍点之中。而sgd的步长是预设的固定值，相对容易跨过一些鞍点。  
拓展2:当我们用牛顿法来求根，牛顿法是基于一阶导数的。
当我们用牛顿法来优化，牛顿法就是基于二阶导数的。  
3. 从最大似然估计的角度解释、推导线性回归的损失函数是最小二乘，也就是Mean Squared Error。
拓展1:线性回归需要满足四个前提假设

	1. Linearity 线性

应变量和每个自变量都是线性关系。

	2. Indpendence 独立性

对于所有的观测值，它们的误差项相互之间是独立的。

	3. Normality 正态性

误差项服从正态分布。

	4. Equal-variance 等方差

所有的误差项具有同样方差。

这四个假设的首字母，合起来就是LINE，这样很好记。


如果这些假设不满足，最终的回归模型可能不精确乃至比较离谱。其中最重要的假设是线性，如果自变量和应变量本身并非线性关系，那么拟合出来的模型当然会有偏差。比如说，人的身高和年龄，如果是1到15岁，这个线性模型看起来似乎问题不大。那么1到60岁，身高和年龄还是线性关系吗？显然就不是了吧。  
4. 推荐系统中的协同过滤(Collaborative Filtering Recommendation, CF)有哪些优点？
有哪些缺点？  
解：优点主要有：
   1. 共用其他人的经验，避免了物品内容分析的不完全或不精确
   2. 相对于基于物品内容的推荐系统，CF非常个性化
   3. 对物品本身没有局限性，不管是音乐、书籍、餐厅、旅游景点，都可以使用CF
   4. 不依赖于物品本身的属性的提取，免去了复杂的物品特征提取的过程
   5. 可以提取物品本身的隐变量(latent variable)用于对物品进行聚类分析

缺点主要有：
   1. 新用户问题冷启动问题(cold problem for new users), 系统开始时推荐质量较差
   2. 新物品问题(cold problem for new items)，质量取决于历史数据集
   3. 稀疏性问题(sparsity)
   4. 系统延伸性问题(scalability)，大型矩阵计算量大并且在线训练(online learning)较难  
5. 解释梯度、雅可比矩阵矩阵和海塞矩阵。 
梯度(gradient)和海塞矩阵(Hessian matrix)都是针对f:Rn→R的函数，也就是多变量的单值函数。它们分别代表一阶导数和二阶导数。
雅可比矩阵(Jacobian matrix)都是针对f:Rn→Rm的函数，也就是多变量的多值函数。雅可比矩阵表征了一阶导数的情况。

#卷42
5. 什么是p value？Type I error和Type II error分别是什么？  
p value是假设检验中的基本概念。p value是在零假设下，我们测量到观测值或者有甚于观测值的概率。这个概率越小，我们越趋近拒绝零假设。


Type I error（第一类型错误）：原假设是正确的，我们却拒绝原假设。
Type II error（第二类型错误）：原假设是错误的，我们却没有拒绝原假设。  
拓展1:p值本身是一个概率：在零假设下，观测值或者有甚于观测值发生的概率。这个概率越小，我们越趋近拒绝零假设。
这里比较特殊的是所谓的“有甚于”。比如说我们有一个正态分布，我们的零假设是这个分布的期望是0，对立假设是期望不等于0。我们从这个分布里随机取了100个数作为样本，这一百个数的均值是1。那p值就是在这个正态分布期望为0的前提下，这个样本的均值等于正负1，或者大于1，或者小于-1的概率。有甚于在这里就是大于1或者小于-1的意思。  
拓展2:多重检验中的FDR(false discovery rate, 错误发现率)是什么？  
假如我们进行了一个有m个零假设的多重假设检验，我们拒绝了其中的R个假设，在这R个假设中又有T1个假设是被我们错误地拒绝了，也就是说有T1

个Type I error。FDR的定义如下

FDR=E(T<sub>1</sub>/max{R,1}).

如果FDR<α
，我们就说这个多重检验的FDR被控制在了α水平。  
FDR就是错误发现率，在二元分类中，比如你的算法“发现”了10个阳性，实际上其中3个你搞错了，FDR=0.3

FDR=FP/(TP+FP)=1−Precision=1−PPV

#卷43
1. 假设你现在有LinkedIn上所有用户的各项数据，你如何预测某个用户这三个月内是否跳槽？你准备使用哪些数据？使用什么模型？  
解：首先，很明显这是一个二元分类的问题。1代表三个月内跳槽；0代表三个月内并没有跳槽。因为涉及到跳槽，所以我们也只需要针对目前有工作的用户，排除在读学生和应届生。

既然是监督式学习，就要考虑如何构建training data。
一种思路是: 在过去的历史数据中，每三个月的第一天，对用户信息进行快照(snapshot)，并跟踪三个月观测他们是否跳槽。比如说，我们回看过去3年的数据
  - 2015年6月1日，对所有用户进行快照取得训练数据，跟踪用户在2015年6月1日到2015年8月31日内是否跳槽。
  - 2015年9月1日，对所有用户进行快照取得训练数据，跟踪用户在2015年9月1日到2015年11月30日内是否跳槽。
  - 2015年12月1日，对所有用户进行快照取得训练数据，跟踪用户在2015年12月1日到2016年2月29日内是否跳槽。
  - ...
  - 2018年6月1日，对所有用户进行快照取得训练数据，跟踪用户在2018年6月1日到2018年8月30日内是否跳槽。


下面就要具体去考虑需要收集的信息，为训练做准备。
要收集的信息可以包括用户基本资料、在snapshot的时刻用户历史数据以及行为以及整个市场的供需状况。

  	1. 用户资料
特征包括：毕业年份、毕业学校、专业、之前的公司、当前的公司、目前的职位、职位的级别、在当前职位的时间长度、在当前公司的时间长度，等等。

  	2. Snapshot时的数据以及用户行为。
一个是snapshot的年、月、日信息（比如年初跳槽就比较高发）。行为包括：截止到snapshot的时间用户在Linkedin有多少人脉联系人(connections)，最近一周、一个月、两个月、三个月、半年新增的connections个数，新增connections中HR的个数，最近一周、一个月、两个月、三个月、半年访问Linkedin的次数，最近一次更新简历至今的天数、最近一次增加技能至今的天数，最近一周、一个月、两个月、三个月、半年在Linkedin搜索职位的次数，最近一周、一个月、两个月、三个月、半年在Linkedin与HR发消息的次数等等。

  	3. 整个市场的供需状况。
对每个行业/领域/地区，过去每月在Linkedin新发布的职位的个数。

下一个步骤就是建立预测模型。
常见二元分类模型包括逻辑回归、随机森林、gbdt/xgboost等。上述提到了很多相关性较强的变量，所以可以使用树类模型或者带正则项的逻辑回归。需要注意的是，这个二元分类显然是非平衡的，1的比例非常少；样本可以通过欠采样或者SMOTE进行预处理，此外也要考虑到模型评价标准的选择。如果最终预测结果为概率，可以使用ROC AUC；如果最终输出结果是0、1标签，可以选择是kappa值。 
(kappa statistic怎么理解？有什么意义？http://sofasofa.io/forum_main_post.php?postid=1000321 )  
(什么是SMOTE sampling方法？http://sofasofa.io/forum_main_post.php?postid=1000817 )  
2. Twitter上有很多假账号，他们影响到很多用户的正常使用。
如果你有Twitter上所有用户的信息，以及一些被标记出来的假账号，你怎么利用这些信息来检测出Twitter上的假账号？
如果你有Twitter上所有用户的信息，但是这些用户都没有被标记，那么你怎么利用这些信息来检测出Twitter上的假账号？  
解：这个问题是典型的异常检测(anomaly detection)。
根据题意，第一个问题是有监督的异常检测，而第二个问题是无监督的异常检测。

下一步就是根据Twitter的场景来选择特征构造数据集。
    1.  用户头像。
特征包括：用户是否上传头像、头像的分辨率、近一年更换头像的次数。假账号往往没有头像、或者使用系统默认头像、或者低分辨率头像，而且一旦设定就很少再换了。

    2.  用户资料。
特征包括：用户是否有自我介绍、用户是否选择了性别、是否选择了地区、是否填写了其他信息、是否绑定了其他社交账号、是否设置个性化的页面短链接。

    3.  互粉情况。
特征包括：用户follow了多少人、被多少人follow、两者的比例、有多少人与该用户是互粉的。通常假账号会follow很多人，但是却没有很多粉丝。

    4.  发推文情况。
特征包括：发推文的个数、、发推文的时间段、推文中是否含有地理定位、推文中是否带有超链接。假账号发的推文常带有超链接、却很少带有地理定位，而且发推文的时间段可能是全天时段的。

    5.  与他人互动情况。
特征包括：用户的推文是否被转载、该用户是否转发过他人的推文、与他人是否有评论、私信的互动。


监督式异常检测
下一步就是建立二元分类模型，值得注意的是这里非平衡问题，所以要进行适当的预处理、选择适当的模型以及模型评判标准。
在回答建立模型这一部分，请选择自己擅长的模型，因为面试官会根据求职者选择的模型深挖模型细节。


非监督式异常检测
非监督式异常检测又分为基于模型和基于统计量的。
常见模型包括one-class SVM, Isolation Forests，Autoencoder（Replicator Neural Networks, 教程以及代码实战http://sofasofa.io/tutorials/anomaly_detection/ ），DBSCAN，GMM，等。同样，在回答建立模型这一部分，请选择自己擅长的模型，因为面试官会根据求职者选择的模型深挖模型细节。
基于统计量的方法通常基于假设检验，其思想是原假设是该用户服从整体用户的分布，对立假设是该用户不来自整体用户的分布，然后对假设检验的p-value设定阈值。  
3. 准确预测产品的效率有助于仓储、物流的调控。如果你有过去该商品在各个门店每周的销量，你如何建立模型预测未来的销量？
除了销量信息，你还想获取哪些有助于模型的信息？
如何评判模型的准确度？  
解：第一个问题是一个一元变量的时间序列问题。这类问题的经典解法是AR，ARMA以及ARIMA和SARIMA模型。
此外也可以考虑非线性模型，比如Random Forest或者Boosting，但是在使用这类模型时首先需要de-trend，就是先用线性模型拟合，让整个时间序列平稳，然后再用随机森林或者boosting。此外还有注意合成一些时间变量，比如这周是否是节日等等。
因为需要预测多个门店的销量，所以可以选择每个门店一个模型也可以让门店成为模型中的一个特征。此外，也可以尝试RNN等神经网络模型。

这个部分是非常主观的，答案可以各种各样，可供参考的其他有助于模型提高精度的信息包括：
    1.  促销打折信息。需要过去该商品的促销打折信息，以及未来的促销打折计划。
    2.  其他同类产品过去的销量。
    3.  各个门店所在地的消费价格指数CPI。
    4.  各个门店所在地的天气状况。
    5.  各个门店所在地是否有大型活动、突发事故等。

时间序列无法进行交叉验证，否则会发生data leakage。可行的方法是，用前m个月的数据进行训练，用后n个月进行验证。因为这是一个回归问题，所以评价标准可以使用RMSE，MAE，MAPE等。   
SARIMAX是什么算法？http://sofasofa.io/forum_main_post.php?postid=1002690  
怎么对时间序列进行交叉验证？http://www.sofasofa.io/forum_main_post.php?postid=1001106  
除了RMSE，评价回归模型有哪些常用的metric？http://sofasofa.io/forum_main_post.php?postid=1000642  
什么是数据泄漏？数据泄露就是说用了不该用的数据，比如

    1.在训练模型时，利用了测试集的数据、信息
    2.在当前使用了未来的数据
    3.在交叉验证进行调参时，使用了验证集的信息参与模型建立

具体说下第三点，比如对特征进行标准化，正确的方法应该是在训练集上标准化，然后应用到验证集上，而非先标准化，再划分验证集。再比如说，要对数据进行pca降维，应该是在训练集上pca，然后作用到验证集上，而非对整个数据集进行pca。通常都忽略了这一点。  

#卷44
1.AdaBoost和GBDT的主要相同点和区别是什么？  
解：相同点：
   1. 都是加性模型
   2. 每一步训练一个弱学习器（通常是决策树）以弥补前面模型的不足

不同点：
   1. AdaBoost中当前学习器的“不足”由样本权重来决定
   2. GBDT中当前学习器的“不足”由求梯度决定
   3. GBDT是Adaboost的推广，GBDT可以使用不同的损失函数   
拓展：adaboost做回归预测的时候，是怎么调整样本权重的？http://sofasofa.io/forum_main_post.php?postid=1003214  
2. 为什么我们不能用最小二乘法来解决二元分类问题？
换句话说，我们为什么不能用平方误差(MSE)作为逻辑回归的损失函数？  
解：从下面几个方面，我们都可以看出MSE是不适合作为逻辑回归的损失函数的：

   	1. MSE不是accuracy的良性代理函数（可参考拓展阅读中的答案）
   	2. 最大似然估计的角度来说，logloss是最适合二元分类的损失函数
   	3. 如果用MSE作为逻辑回归的损失函数，那么这个损失函数本身不是凸函数，而是有很多的局部最优
   	4. 如果用MSE作为逻辑回归的损失函数，容易发生梯度消失  

拓展：  
怎么理解surrogate loss function代理损失函数？http://sofasofa.io/forum_main_post.php?postid=1000605   
二元分类为什么不能用MSE做为损失函数？http://sofasofa.io/forum_main_post.php?postid=1001792  
如何推导逻辑回归的损失函数？http://sofasofa.io/forum_main_post.php?postid=1000352  
3. 如何从流数据中均匀取样？
具体来说，数据样本是一个个进入系统，你并不知道数据流何时结束或者数据总个数，在这种情况下，你如何一个流动的数据里随机均匀地选出k个样本？如何证明你的方法是随机均匀的？  
拓展:离线算法是需要输入全部数据之后再开始训练模型。比如说一开始你有1万行数据，你用这个数据训练出了一个模型，当你又有了1千行新数据后，你需要把这1千行和原来的1万行数据合并起来，再重新训练模型。

在线算法则不需要重新训练，在线算法可以按批次接收数据、改进模型。比如说一开始你有1万行数据，你用这个数据训练出了一个模型，当你又有了1百行新数据，你不需要把这些新数据与原数据合并，你可以只利用这100行数据对原先的模型进行调整（不是从头重新训练），再来1百行数据，又可以利用新的数据对模型进行调整。

在线算法的一个巨大优势是节约空间。当数据量特别大的时候，我们可以一部分一部分的训练，而不是直接在整个数据集上训练。  
4. ARIMA中各个组成部分AR，I，MA分别是什么意思？有什么作用？
如果时间序列中有周期性(seasonality)，那么该如何处理？  
解：  1. AR是Auto-Regression，自回归的意思。AR让模型引入了时滞项(lagging terms)。
   2. I是Integrated，差分的意思。这一项的目的是为了让时间序列平稳。
   3. MA是Moving Mverage，移动平均。目的是为了平滑时间序列，减少噪音带来的波动性。

如果我们在时间序列中观测到了周期性，那么我们就需要对应地引入周期性的变量。
例如，如果数据是每月一个观测点并且具有年周期性，当前观测值为Xt，上个月的观测值为Xt−1，那么我们也应该引入变量Xt−12到模型中。  
5. GBDT+LR分类器的原理是什么？
GBDT+LR中，如果GBDT有1000颗树，每个树有100个叶子节点，那么输入到LR的特征会是一个高维稀疏的向量。
它的维度是多少？那么应该如何处理这个高维度问题？   
解：简单来说是将GBDT中每棵树的叶节点作为一个新的特征：每个叶子都对应着一个01变量，如果某样本落在该叶节点上就是1，否则为0。
如果有T棵树，叶子的总数为M，那么每个样本就被转换成一个长度为M的01向量，而每个向量都只含有T个1。
接下来就将这01向量作为逻辑回归模型(LR)的输入。

向量的维度是1000×100=105。
考虑到维度很高，所以我们可以对数据进行降维，比如使用PCA，tSNE或者Autoencoder，然后对降维后的数据进行逻辑回归。  
拓展：GBDT+LR的工作原理是什么？http://sofasofa.io/forum_main_post.php?postid=1002384  
除了PCA，还有什么降维的方法？  
	
	1.High Correlation

	如果两个feature的correlation大于某个阈值（自己设定的，比如0.3），就删掉其中一个。

	2. Low variance

	如果一个feature的数据方差小于某个阈值（自己设定），就把它删掉。

	3. Missing

	如果这一列有很多missing，就把它删掉。

	4. Random Forests

	Random Forests训练之后，可以返回所有特征的重要性，我们可以选择重要性最高的一部分特征，比如20%。

	5. Stepwise selection

	逐步选择特征，可以向前选择，也可以向后消去。

	6. Random Projection

	类似于PCA，但是这个投影是随机的，而非像PCA那样是正交的。
	
	7. AutoEncoder

	类似于word2vec，我们只提取神经网络的中间层的结果作为降维的结果，当激活函数都是线性时，效果与PCA相似  
















